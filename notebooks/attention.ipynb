{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self-Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, d_in, d_out_kq, d_out_v):\n",
    "        super().__init__()\n",
    "        self.d_out_kq = d_out_kq\n",
    "        self.W_query = nn.Linear(d_in, d_out_kq)\n",
    "        self.W_key   = nn.Linear(d_in, d_out_kq)\n",
    "        self.W_value = nn.Linear(d_in, d_out_v)\n",
    "\n",
    "    def forward(self, x):\n",
    "        keys, queries, values = self.W_key(x), self.W_query(x), self.W_value(x)\n",
    "\n",
    "        attn_scores = queries @ keys.transpose(-2,-1)  # unnormalized attention weights\n",
    "        # no mask\n",
    "        attn_weights = torch.softmax(\n",
    "            attn_scores / self.d_out_kq**0.5, dim=-1\n",
    "        )\n",
    "\n",
    "        # # causal mask\n",
    "        # seq_len = attn_weights.shape[0] # seq_len x seq_len\n",
    "        # mask = torch.triu(torch.ones(seq_len, seq_len), diagonal=1)\n",
    "        # masked = attn_scores.masked_fill(mask.bool(), -torch.inf)\n",
    "        # attn_weights = torch.softmax(masked / self.d_out_kq**0.5, dim=1)\n",
    "\n",
    "        context_vec = attn_weights @ values\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_sentence = torch.randn((2, 6, 3)) #b, seq_len, n_dim\n",
    "# reduce d_out_v from 4 to 1, because we have 4 heads\n",
    "d_in, d_out_kq, d_out_v = 3, 2, 4\n",
    "sa = SelfAttention(d_in, d_out_kq, d_out_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-head-Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out_kq, d_out_v, num_heads):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList(\n",
    "            [SelfAttention(d_in, d_out_kq//num_heads, d_out_v//num_heads)\n",
    "             for _ in range(num_heads)]\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return torch.cat([head(x) for head in self.heads], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "mha = MultiHeadAttention(d_in, d_out_kq, d_out_v, num_heads=2)\n",
    "context_vecs = mha(embedded_sentence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporal Mixing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "consists of 2 layers - conv3d and temporal attention applied after every spatial layer\n",
    "\n",
    "![image.png](../imgs/vid.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from einops import rearrange\n",
    "import torch.nn.functional as F\n",
    "from einops.layers.torch import Rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv3DLayer(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, n_frames):\n",
    "        super().__init__()\n",
    "\n",
    "        self.to_3d = Rearrange('(b t) c h w -> b c t h w', t=n_frames)\n",
    "        self.to_2d = Rearrange('b c t h w -> (b t) c h w')\n",
    "\n",
    "        k, p = (3, 1, 1), (1, 0, 0)\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.GroupNorm(32, in_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv3d(in_dim, out_dim, kernel_size=k, stride=1, padding=p)\n",
    "        )\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.GroupNorm(32, out_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv3d(out_dim, out_dim, kernel_size=k, stride=1, padding=p)\n",
    "        )\n",
    "        self.alpha = nn.Parameter(torch.ones(1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.to_3d(x)\n",
    "\n",
    "        h = self.block1(h)\n",
    "        h = self.block2(h)\n",
    "\n",
    "        h = self.to_2d(h)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            self.alpha.clamp_(0, 1)\n",
    "        out = self.alpha * x + (1 - self.alpha) * h\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalAttentionLayer(nn.Module):\n",
    "    def __init__(self, dim=64, n_frames=5, n_heads=8, kv_dim=None):\n",
    "        super().__init__()\n",
    "        self.n_frames = n_frames\n",
    "        self.alpha = nn.Parameter(torch.ones(1))\n",
    "        self.mha = MultiHeadAttention(d_in=dim, d_out_kq=dim, d_out_v=dim, num_heads=n_heads)\n",
    "\n",
    "    def forward(self, q, kv=None, mask=None):\n",
    "        skip = q\n",
    "        bt, c, h, w = q.shape\n",
    "        q = rearrange(q, '(b t) c h w -> (b h w) t c', t=self.n_frames)\n",
    "        out = self.mha(q)\n",
    "        out = rearrange(out, '(b h w) t c -> (b t) c h w', h=h, w=w)\n",
    "        with torch.no_grad():\n",
    "            self.alpha.clamp_(0, 1)\n",
    "        out = self.alpha * skip + (1 - self.alpha) * out\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 64, 32, 32])\n",
      "torch.Size([2048, 5, 64])\n",
      "torch.Size([10, 64, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "t = TemporalAttentionLayer(dim=2*32*32, n_frames=5)\n",
    "# bt, c, h, w\n",
    "q = torch.randn(2*5,64,32,32)\n",
    "out = t(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
