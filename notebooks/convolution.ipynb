{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D convolution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolve(signal, kernel):\n",
    "    output = []\n",
    "    kernel_size = len(kernel)\n",
    "    padding = kernel_size // 2 # assume zero padding\n",
    "    padded_signal = [0] * padding + signal + [0] * padding\n",
    "    \n",
    "    for i in range(padding, len(signal) + padding):\n",
    "        sum = 0\n",
    "        for j in range(kernel_size):\n",
    "            sum += kernel[j] * padded_signal[i - padding + j]\n",
    "        output.append(sum)\n",
    "    \n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2, -2, -2, -2, -2, 5]\n"
     ]
    }
   ],
   "source": [
    "signal = [1, 2, 3, 4, 5, 6]\n",
    "kernel = [1, 0, -1]\n",
    "output = convolve(signal, kernel)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D convolution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def convolution(image, kernel):\n",
    "    # get the size of the input image and kernel\n",
    "    (image_height, image_width, image_channels) = image.shape\n",
    "    (kernel_height, kernel_width, kernel_channels) = kernel.shape\n",
    "    \n",
    "    # calculate the padding needed for 'same' convolution\n",
    "    pad_h = (kernel_height - 1) // 2\n",
    "    pad_w = (kernel_width - 1) // 2\n",
    "    \n",
    "    # pad the input image with zeros\n",
    "    padded_image = np.pad(image, ((pad_h, pad_h), (pad_w, pad_w), (0, 0)), 'constant')\n",
    "    \n",
    "    # create an empty output tensor\n",
    "    output_height = image_height\n",
    "    output_width = image_width\n",
    "    output_channels = kernel_channels\n",
    "    output = np.zeros((output_height, output_width, output_channels))\n",
    "    \n",
    "    # perform the convolution operation\n",
    "    for i in range(output_height):\n",
    "        for j in range(output_width):\n",
    "            for k in range(output_channels):\n",
    "                output[i, j, k] = np.sum(kernel[:, :, k:k+1] * \n",
    "                                         padded_image[i:i+kernel_height, j:j+kernel_width, :])\n",
    "    \n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = np.random.randn(32,32,10)\n",
    "kernel = np.random.randn(3,3,3)\n",
    "out = convolution(image, kernel)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an example image and kernel\n",
    "image = np.array([[[1, 2], [3, 4]], [[5, 6], [7, 8]], [[9, 10], [11, 12]]])\n",
    "kernel = np.array([[[1, 0], [0, -1]], [[0, 1], [-1, 0]]])\n",
    "\n",
    "output = convolution(image, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def convolution(image, kernel, padding=0, stride=1):\n",
    "    # Get dimensions of image and kernel\n",
    "    (image_height, image_width, image_channels) = image.shape\n",
    "    (kernel_height, kernel_width, kernel_channels) = kernel.shape\n",
    "\n",
    "    # Calculate the output dimensions\n",
    "    output_height = (image_height - kernel_height + 2 * padding) // stride + 1\n",
    "    output_width = (image_width - kernel_width + 2 * padding) // stride + 1\n",
    "    output_channels = kernel_channels\n",
    "\n",
    "    # Pad the image\n",
    "    padded_image = np.pad(image, ((padding, padding), (padding, padding), (0, 0)), mode='constant')\n",
    "    \n",
    "    # Initialize the output matrix\n",
    "    output = np.zeros((output_height, output_width, output_channels))\n",
    "\n",
    "    # Perform the convolution\n",
    "    for i in range(output_height):\n",
    "        for j in range(output_width):\n",
    "            for k in range(output_channels):\n",
    "              h_start = i * stride\n",
    "              h_end = h_start + kernel_height\n",
    "              w_start = j * stride\n",
    "              w_end = w_start + kernel_width\n",
    "              output[i, j, k] = np.sum(kernel[:, :, k:k+1] * padded_image[h_start:h_end, w_start:w_end, :])\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of convolution:\n",
      "(17, 4, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "image = np.random.randn(32,5,10)\n",
    "kernel = np.random.randn(3,3,3)\n",
    "padding = 2\n",
    "stride = 2\n",
    "\n",
    "result = convolution(image, kernel, padding, stride)\n",
    "print(\"Result of convolution:\")\n",
    "print(result.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def convolution(image, kernel, padding=0, stride=1, groups=1):\n",
    "    # Get dimensions of image and kernel\n",
    "    (image_height, image_width, image_channels) = image.shape\n",
    "    (kernel_height, kernel_width, kernel_channels) = kernel.shape\n",
    "\n",
    "    # Calculate the output dimensions\n",
    "    output_height = (image_height - kernel_height + 2 * padding) // stride + 1\n",
    "    output_width = (image_width - kernel_width + 2 * padding) // stride + 1\n",
    "    output_channels = kernel_channels\n",
    "\n",
    "    # Pad the image\n",
    "    padded_image = np.pad(image, ((padding, padding), (padding, padding), (0, 0)), mode='constant')\n",
    "\n",
    "    # Initialize the output matrix\n",
    "    output = np.zeros((output_height, output_width, output_channels))\n",
    "\n",
    "    # Perform the convolution\n",
    "    for g in range(groups):\n",
    "        # Divide input image and kernel into groups\n",
    "        image_group = padded_image[:, :, g * (image_channels // groups):(g + 1) * (image_channels // groups)]\n",
    "        kernel_group = kernel[:, :, g * (kernel_channels // groups):(g + 1) * (kernel_channels // groups)]\n",
    "\n",
    "        for i in range(output_height):\n",
    "            for j in range(output_width):\n",
    "                for k in range(output_channels // groups):\n",
    "                    h_start = i * stride\n",
    "                    h_end = h_start + kernel_height\n",
    "                    w_start = j * stride\n",
    "                    w_end = w_start + kernel_width\n",
    "                    output[i, j, g * (output_channels // groups) + k] = np.sum(\n",
    "                        kernel_group[:, :, k] * image_group[h_start:h_end, w_start:w_end])\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D Conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from einops.layers.torch import Rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv3DLayer(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, n_frames):\n",
    "        super().__init__()\n",
    "\n",
    "        self.to_3d = Rearrange('(b t) c h w -> b c t h w', t=n_frames)\n",
    "        self.to_2d = Rearrange('b c t h w -> (b t) c h w')\n",
    "\n",
    "        k, p = (3, 1, 1), (1, 0, 0)\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.GroupNorm(32, in_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv3d(in_dim, out_dim, kernel_size=k, stride=1, padding=p)\n",
    "        )\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.GroupNorm(32, out_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv3d(out_dim, out_dim, kernel_size=k, stride=1, padding=p)\n",
    "        )\n",
    "\n",
    "        self.alpha = nn.Parameter(torch.ones(1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.to_3d(x)\n",
    "\n",
    "        h = self.block1(h)\n",
    "        h = self.block2(h)\n",
    "\n",
    "        h = self.to_2d(h)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            self.alpha.clamp_(0, 1)\n",
    "\n",
    "        out = self.alpha * x + (1 - self.alpha) * h\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patchify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def patchify_bf(img, patch_size):\n",
    "    patches = []\n",
    "    C, H, W = img.shape\n",
    "    patch_H, patch_W = patch_size\n",
    "    pad_H = patch_H - H % patch_H if H % patch_H != 0 else 0\n",
    "    pad_W = patch_W - W % patch_W if W % patch_W != 0 else 0\n",
    "\n",
    "    img = np.pad(img, ((0, 0), (0, pad_H), (0, pad_W)))\n",
    "\n",
    "    for i in range(0, H, patch_H):\n",
    "        for j in range(0, W, patch_W):\n",
    "            patches.append(img[:, i : i + patch_H, j : j + patch_W])\n",
    "\n",
    "    return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[  0   1   2   3   4   5   6   7   8   9  10  11]\n",
      "  [ 12  13  14  15  16  17  18  19  20  21  22  23]\n",
      "  [ 24  25  26  27  28  29  30  31  32  33  34  35]\n",
      "  [ 36  37  38  39  40  41  42  43  44  45  46  47]\n",
      "  [ 48  49  50  51  52  53  54  55  56  57  58  59]\n",
      "  [ 60  61  62  63  64  65  66  67  68  69  70  71]\n",
      "  [ 72  73  74  75  76  77  78  79  80  81  82  83]\n",
      "  [ 84  85  86  87  88  89  90  91  92  93  94  95]\n",
      "  [ 96  97  98  99 100 101 102 103 104 105 106 107]\n",
      "  [108 109 110 111 112 113 114 115 116 117 118 119]]]\n",
      "[array([[[ 0,  1,  2,  3,  4],\n",
      "        [12, 13, 14, 15, 16],\n",
      "        [24, 25, 26, 27, 28],\n",
      "        [36, 37, 38, 39, 40],\n",
      "        [48, 49, 50, 51, 52]]]), array([[[ 5,  6,  7,  8,  9],\n",
      "        [17, 18, 19, 20, 21],\n",
      "        [29, 30, 31, 32, 33],\n",
      "        [41, 42, 43, 44, 45],\n",
      "        [53, 54, 55, 56, 57]]]), array([[[10, 11,  0,  0,  0],\n",
      "        [22, 23,  0,  0,  0],\n",
      "        [34, 35,  0,  0,  0],\n",
      "        [46, 47,  0,  0,  0],\n",
      "        [58, 59,  0,  0,  0]]]), array([[[ 60,  61,  62,  63,  64],\n",
      "        [ 72,  73,  74,  75,  76],\n",
      "        [ 84,  85,  86,  87,  88],\n",
      "        [ 96,  97,  98,  99, 100],\n",
      "        [108, 109, 110, 111, 112]]]), array([[[ 65,  66,  67,  68,  69],\n",
      "        [ 77,  78,  79,  80,  81],\n",
      "        [ 89,  90,  91,  92,  93],\n",
      "        [101, 102, 103, 104, 105],\n",
      "        [113, 114, 115, 116, 117]]]), array([[[ 70,  71,   0,   0,   0],\n",
      "        [ 82,  83,   0,   0,   0],\n",
      "        [ 94,  95,   0,   0,   0],\n",
      "        [106, 107,   0,   0,   0],\n",
      "        [118, 119,   0,   0,   0]]])]\n"
     ]
    }
   ],
   "source": [
    "H, W = 10, 12\n",
    "patch_size = (5, 5)\n",
    "img = np.arange(H * W * 1).reshape(1, H, W)\n",
    "print(img)\n",
    "\n",
    "patches_bf = patchify_bf(img, patch_size)\n",
    "print(patches_bf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tester\n",
    "def patchify_opt(img, patch_size):\n",
    "    C, H, W = img.shape\n",
    "    patch_H, patch_W = patch_size\n",
    "    pad_H = patch_H - H % patch_H if H % patch_H != 0 else 0\n",
    "    pad_W = patch_W - W % patch_W if W % patch_W != 0 else 0\n",
    "    new_H = H + pad_H\n",
    "    new_W = W + pad_W\n",
    "\n",
    "    img = np.pad(img, ((0, 0), (0, pad_H), (0, pad_W)))\n",
    "\n",
    "    st_C, st_H, st_W = img.strides\n",
    "    patches = np.lib.stride_tricks.as_strided(\n",
    "        img,\n",
    "        (new_H // patch_H, new_W // patch_W, C, patch_H, patch_W),\n",
    "        (st_H * patch_H, st_W * patch_W, st_C, st_H, st_W),\n",
    "    )\n",
    "\n",
    "    return patches.reshape(-1, C, patch_H, patch_W)\n",
    "\n",
    "patches_opt = patchify_opt(img, patch_size)\n",
    "assert (patches_opt == patches_bf).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
